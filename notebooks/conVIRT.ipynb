{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00821abe-d293-4f45-9a4e-aa4ee300a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class ModelCLR(nn.Module):\n",
    "    def __init__(self, res_base_model, bert_base_model, out_dim, freeze_layers, do_lower_case):\n",
    "        super(ModelCLR, self).__init__()\n",
    "        #init BERT\n",
    "        self.bert_model = self._get_bert_basemodel(bert_base_model,freeze_layers)\n",
    "        # projection MLP for BERT model\n",
    "        self.bert_l1 = nn.Linear(768, 768) #768 is the size of the BERT embbedings\n",
    "        self.bert_l2 = nn.Linear(768, out_dim) #768 is the size of the BERT embbedings\n",
    "\n",
    "        # init Resnet\n",
    "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False),\n",
    "                            \"resnet50\": models.resnet50(pretrained=False)}\n",
    "        resnet = self._get_res_basemodel(res_base_model)\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        self.res_features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        # projection MLP for ResNet Model\n",
    "        self.res_l1 = nn.Linear(num_ftrs, num_ftrs)\n",
    "        self.res_l2 = nn.Linear(num_ftrs, out_dim)\n",
    "\n",
    "    def _get_res_basemodel(self, res_model_name):\n",
    "        try:\n",
    "            res_model = self.resnet_dict[res_model_name]\n",
    "            print(\"Image feature extractor:\", res_model_name)\n",
    "            return res_model\n",
    "        except:\n",
    "            raise (\"Invalid model name. Check the config file and pass one of: resnet18 or resnet50\")\n",
    "\n",
    "    def _get_bert_basemodel(self, bert_model_name, freeze_layers):\n",
    "        try:\n",
    "            model = AutoModel.from_pretrained(bert_model_name)#, return_dict=True)\n",
    "            print(\"Image feature extractor:\", bert_model_name)\n",
    "        except:\n",
    "            raise (\"Invalid model name. Check the config file and pass a BERT model from transformers library\")\n",
    "\n",
    "        if freeze_layers is not None:\n",
    "            for layer_idx in freeze_layers:\n",
    "                for param in list(model.encoder.layer[layer_idx].parameters()):\n",
    "                    param.requires_grad = False\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Mean Pooling - Take attention mask into account for correct averaging\n",
    "        Reference: https://www.sbert.net/docs/usage/computing_sentence_embeddings.html\n",
    "        \"\"\"\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def image_encoder(self, xis):\n",
    "        h = self.res_features(xis)\n",
    "        h = h.squeeze()\n",
    "\n",
    "        x = self.res_l1(h)\n",
    "        x = F.relu(x)\n",
    "        x = self.res_l2(x)\n",
    "\n",
    "        return h, x\n",
    "\n",
    "    def text_encoder(self, encoded_inputs):\n",
    "        \"\"\"\n",
    "        Obter os inputs e em seguida extrair os hidden layers e fazer a media de todos os tokens\n",
    "        Fontes:\n",
    "        - https://github.com/BramVanroy/bert-for-inference/blob/master/introduction-to-bert.ipynb\n",
    "        - Nils Reimers, Iryna Gurevych. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\n",
    "        https://www.sbert.net\n",
    "        \"\"\"\n",
    "        outputs = self.bert_model(**encoded_inputs)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sentence_embeddings = self.mean_pooling(outputs, encoded_inputs['attention_mask']).half()\n",
    "            x = self.bert_l1(sentence_embeddings)\n",
    "            x = F.relu(x)\n",
    "            out_emb = self.bert_l2(x)\n",
    "\n",
    "        return out_emb\n",
    "\n",
    "    def forward(self, xis, encoded_inputs):\n",
    "\n",
    "        h, zis = self.image_encoder(xis)\n",
    "\n",
    "        zls = self.text_encoder(encoded_inputs)\n",
    "\n",
    "        return zis, zls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MML SSL",
   "language": "python",
   "name": "mml-ssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
