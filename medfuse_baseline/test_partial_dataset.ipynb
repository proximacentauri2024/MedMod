{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9b96e-2fb6-4587-aee8-a58e7c339b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 CUDA_LAUNCH_BLOCKING=1 python fusion_main.py \\\n",
    "--dim 256 --dropout 0.3 --layers 2 \\\n",
    "--vision-backbone resnet34 \\\n",
    "--mode train \\\n",
    "--epochs 50 --batch_size 16 \\\n",
    "--vision_num_classes 14 --num_classes 1 \\\n",
    "--data_pairs partial_ehr_cxr \\\n",
    "--data_ratio 1.0 \\\n",
    "--task in-hospital-mortality \\\n",
    "--labels_set mortality \\\n",
    "--fusion_type lstm \\\n",
    "--save_dir checkpoints/mortality/medFuse \\\n",
    "--load_state_ehr checkpoints/mortality/uni_ehr_all/best_checkpoint.pth.tar \\\n",
    "--load_state_cxr checkpoints/cxr_rad_full/best_checkpoint.pth.tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86588bfc-4904-4ce1-bad5-ff45fcd40ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# import \n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "R_CLASSES  = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "       'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "       'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other',\n",
    "       'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "CLASSES = [\n",
    "       'Acute and unspecified renal failure', 'Acute cerebrovascular disease',\n",
    "       'Acute myocardial infarction', 'Cardiac dysrhythmias',\n",
    "       'Chronic kidney disease',\n",
    "       'Chronic obstructive pulmonary disease and bronchiectasis',\n",
    "       'Complications of surgical procedures or medical care',\n",
    "       'Conduction disorders', 'Congestive heart failure; nonhypertensive',\n",
    "       'Coronary atherosclerosis and other heart disease',\n",
    "       'Diabetes mellitus with complications',\n",
    "       'Diabetes mellitus without complication',\n",
    "       'Disorders of lipid metabolism', 'Essential hypertension',\n",
    "       'Fluid and electrolyte disorders', 'Gastrointestinal hemorrhage',\n",
    "       'Hypertension with complications and secondary hypertension',\n",
    "       'Other liver diseases', 'Other lower respiratory disease',\n",
    "       'Other upper respiratory disease',\n",
    "       'Pleurisy; pneumothorax; pulmonary collapse',\n",
    "       'Pneumonia (except that caused by tuberculosis or sexually transmitted disease)',\n",
    "       'Respiratory failure; insufficiency; arrest (adult)',\n",
    "       'Septicemia (except in labor)', 'Shock'\n",
    "    ]\n",
    "\n",
    "class MIMIC_CXR_EHR(Dataset):\n",
    "    def __init__(self, args, metadata_with_labels, ehr_ds, cxr_ds, split='train'):\n",
    "        \n",
    "        self.CLASSES = CLASSES\n",
    "        if 'radiology' in args.labels_set:\n",
    "            self.CLASSES = R_CLASSES\n",
    "        \n",
    "        self.metadata_with_labels = metadata_with_labels\n",
    "        self.cxr_files_paired = self.metadata_with_labels.dicom_id.values\n",
    "        self.ehr_files_paired = (self.metadata_with_labels['stay'].values)\n",
    "        self.cxr_files_all = cxr_ds.filenames_loaded\n",
    "        self.ehr_files_all = ehr_ds.names\n",
    "        self.ehr_files_unpaired = list(set(self.ehr_files_all) - set(self.ehr_files_paired))\n",
    "        self.ehr_ds = ehr_ds\n",
    "        self.cxr_ds = cxr_ds\n",
    "        self.args = args\n",
    "        self.split = split\n",
    "        self.data_ratio = self.args.data_ratio \n",
    "        if split=='test':\n",
    "            self.data_ratio =  1.0\n",
    "        elif split == 'val':\n",
    "            self.data_ratio =  0.0\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.args.data_pairs == 'paired_ehr_cxr':\n",
    "            ehr_data, labels_ehr = self.ehr_ds[self.ehr_files_paired[index]]\n",
    "            cxr_data, labels_cxr = self.cxr_ds[self.cxr_files_paired[index]]\n",
    "            return ehr_data, cxr_data, labels_ehr, labels_cxr\n",
    "        elif self.args.data_pairs == 'paired_ehr':\n",
    "            ehr_data, labels_ehr = self.ehr_ds[self.ehr_files_paired[index]]\n",
    "            cxr_data, labels_cxr = None, None\n",
    "            return ehr_data, cxr_data, labels_ehr, labels_cxr\n",
    "        elif self.args.data_pairs == 'radiology':\n",
    "            ehr_data, labels_ehr = np.zeros((1, 10)), np.zeros(self.args.num_classes)\n",
    "            cxr_data, labels_cxr = self.cxr_ds[self.cxr_files_all[index]]\n",
    "            return ehr_data, cxr_data, labels_ehr, labels_cxr\n",
    "        elif self.args.data_pairs == 'partial_ehr':\n",
    "            ehr_data, labels_ehr = self.ehr_ds[self.ehr_files_all[index]]\n",
    "            cxr_data, labels_cxr = None, None\n",
    "            return ehr_data, cxr_data, labels_ehr, labels_cxr\n",
    "        \n",
    "        elif self.args.data_pairs == 'partial_ehr_cxr':\n",
    "            if index < len(self.ehr_files_paired):\n",
    "                ehr_data, labels_ehr = self.ehr_ds[self.ehr_files_paired[index]]\n",
    "                cxr_data, labels_cxr = self.cxr_ds[self.cxr_files_paired[index]]\n",
    "            else:\n",
    "                index = random.randint(0, len(self.ehr_files_unpaired)-1) \n",
    "                ehr_data, labels_ehr = self.ehr_ds[self.ehr_files_unpaired[index]]\n",
    "                cxr_data, labels_cxr = None, None\n",
    "            return ehr_data, cxr_data, labels_ehr, labels_cxr\n",
    "\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        if 'paired' in self.args.data_pairs:\n",
    "            return len(self.ehr_files_paired)\n",
    "        elif self.args.data_pairs == 'partial_ehr':\n",
    "            return len(self.ehr_files_all)\n",
    "        elif self.args.data_pairs == 'radiology':\n",
    "            return len(self.cxr_files_all)\n",
    "        elif self.args.data_pairs == 'partial_ehr_cxr':\n",
    "            return len(self.ehr_files_paired) + int(self.data_ratio * len(self.ehr_files_unpaired)) \n",
    "        \n",
    "\n",
    "\n",
    "def loadmetadata(args):\n",
    "\n",
    "    data_dir = args.cxr_data_dir\n",
    "    cxr_metadata = pd.read_csv(f'{data_dir}/mimic-cxr-2.0.0-metadata.csv')\n",
    "    icu_stay_metadata = pd.read_csv(f'{args.ehr_data_dir}/root/all_stays.csv')\n",
    "    columns = ['subject_id', 'stay_id', 'intime', 'outtime']\n",
    "    \n",
    "    # only common subjects with both icu stay and an xray\n",
    "    cxr_merged_icustays = cxr_metadata.merge(icu_stay_metadata[columns ], how='inner', on='subject_id')\n",
    "    \n",
    "    # combine study date time\n",
    "    cxr_merged_icustays['StudyTime'] = cxr_merged_icustays['StudyTime'].apply(lambda x: f'{int(float(x)):06}' )\n",
    "    cxr_merged_icustays['StudyDateTime'] = pd.to_datetime(cxr_merged_icustays['StudyDate'].astype(str) + ' ' + cxr_merged_icustays['StudyTime'].astype(str) ,format=\"%Y%m%d %H%M%S\")\n",
    "    \n",
    "    cxr_merged_icustays.intime=pd.to_datetime(cxr_merged_icustays.intime)\n",
    "    cxr_merged_icustays.outtime=pd.to_datetime(cxr_merged_icustays.outtime)\n",
    "    end_time = cxr_merged_icustays.outtime\n",
    "    if args.task == 'in-hospital-mortality':\n",
    "        end_time = cxr_merged_icustays.intime + pd.DateOffset(hours=48)\n",
    "\n",
    "    cxr_merged_icustays_during = cxr_merged_icustays.loc[(cxr_merged_icustays.StudyDateTime>=cxr_merged_icustays.intime)&((cxr_merged_icustays.StudyDateTime<=end_time))]\n",
    "\n",
    "    # cxr_merged_icustays_during = cxr_merged_icustays.loc[(cxr_merged_icustays.StudyDateTime>=cxr_merged_icustays.intime)&((cxr_merged_icustays.StudyDateTime<=cxr_merged_icustays.outtime))]\n",
    "    # select cxrs with the ViewPosition == 'AP\n",
    "    cxr_merged_icustays_AP = cxr_merged_icustays_during[cxr_merged_icustays_during['ViewPosition'] == 'AP']\n",
    "\n",
    "    groups = cxr_merged_icustays_AP.groupby('stay_id')\n",
    "\n",
    "    groups_selected = []\n",
    "    for group in groups:\n",
    "        # select the latest cxr for the icu stay\n",
    "        selected = group[1].sort_values('StudyDateTime').tail(1).reset_index()\n",
    "        groups_selected.append(selected)\n",
    "    groups = pd.concat(groups_selected, ignore_index=True)\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # groups['cxr_length'] = (groups['StudyDateTime'] - groups['intime']).astype('timedelta64[h]')\n",
    "    return groups\n",
    "\n",
    "# def \n",
    "def load_cxr_ehr(args, ehr_train_ds, ehr_val_ds, cxr_train_ds, cxr_val_ds, ehr_test_ds, cxr_test_ds):\n",
    "\n",
    "    cxr_merged_icustays = loadmetadata(args) \n",
    "\n",
    "    # cxr_merged_icustays['cxr_length'] = (cxr_merged_icustays['StudyDateTime'] - cxr_merged_icustays['intime'] ).astype('timedelta64[h]')\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    splits_labels_train = pd.read_csv(f'{args.ehr_data_dir}/{args.task}/train_listfile.csv')\n",
    "    splits_labels_val = pd.read_csv(f'{args.ehr_data_dir}/{args.task}/val_listfile.csv')\n",
    "    splits_labels_test = pd.read_csv(f'{args.ehr_data_dir}/{args.task}/test_listfile.csv')\n",
    "\n",
    "\n",
    "    train_meta_with_labels = cxr_merged_icustays.merge(splits_labels_train, how='inner', on='stay_id')\n",
    "    val_meta_with_labels = cxr_merged_icustays.merge(splits_labels_val, how='inner', on='stay_id')\n",
    "    test_meta_with_labels = cxr_merged_icustays.merge(splits_labels_test, how='inner', on='stay_id')\n",
    "    \n",
    "    train_ds = MIMIC_CXR_EHR(args, train_meta_with_labels, ehr_train_ds, cxr_train_ds)\n",
    "    val_ds = MIMIC_CXR_EHR(args, val_meta_with_labels, ehr_val_ds, cxr_val_ds, split='val')\n",
    "    test_ds = MIMIC_CXR_EHR(args, test_meta_with_labels, ehr_test_ds, cxr_test_ds, split='test')\n",
    "\n",
    "    # printPrevalence(train_meta_with_labels, args)\n",
    "    # printPrevalence(val_meta_with_labels, args)\n",
    "    # printPrevalence(test_meta_with_labels, args)\n",
    "\n",
    "    # printPrevalence(splits_labels_train, args)\n",
    "    # printPrevalence(splits_labels_val, args)\n",
    "    # printPrevalence(splits_labels_test, args)\n",
    "\n",
    "\n",
    "    train_dl = DataLoader(train_ds, args.batch_size, shuffle=True, collate_fn=my_collate, pin_memory=True, num_workers=16, drop_last=True)\n",
    "    val_dl = DataLoader(val_ds, args.batch_size, shuffle=False, collate_fn=my_collate, pin_memory=True, num_workers=16, drop_last=False)\n",
    "    test_dl = DataLoader(test_ds, args.batch_size, shuffle=False, collate_fn=my_collate, pin_memory=True, num_workers=16, drop_last=False)\n",
    "\n",
    "    return train_dl, val_dl, test_dl\n",
    "\n",
    "def printPrevalence(merged_file, args):\n",
    "    if args.labels_set == 'pheno':\n",
    "        total_rows = len(merged_file)\n",
    "        print(merged_file[CLASSES].sum()/total_rows)\n",
    "    else:\n",
    "        total_rows = len(merged_file)\n",
    "        print(merged_file['y_true'].value_counts())\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "def my_collate(batch):\n",
    "    x = [item[0] for item in batch]\n",
    "    pairs = [False if item[1] is None else True for item in batch]\n",
    "    img = torch.stack([torch.zeros(3, 224, 224) if item[1] is None else item[1] for item in batch])\n",
    "    x, seq_length = pad_zeros(x)\n",
    "    targets_ehr = np.array([item[2] for item in batch])\n",
    "    targets_cxr = torch.stack([torch.zeros(14) if item[3] is None else item[3] for item in batch])\n",
    "    return [x, img, targets_ehr, targets_cxr, seq_length, pairs]\n",
    "\n",
    "def pad_zeros(arr, min_length=None):\n",
    "    dtype = arr[0].dtype\n",
    "    seq_length = [x.shape[0] for x in arr]\n",
    "    max_len = max(seq_length)\n",
    "    ret = [np.concatenate([x, np.zeros((max_len - x.shape[0],) + x.shape[1:], dtype=dtype)], axis=0)\n",
    "           for x in arr]\n",
    "    if (min_length is not None) and ret[0].shape[0] < min_length:\n",
    "        ret = [np.concatenate([x, np.zeros((min_length - x.shape[0],) + x.shape[1:], dtype=dtype)], axis=0)\n",
    "               for x in ret]\n",
    "    return np.array(ret), seq_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MML SSL",
   "language": "python",
   "name": "mml-ssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
